{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatrixViewer Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup General Environment (always run this first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import math\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from IPython.core.display import display, HTML\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "display(HTML(\"<style>.container { width:100% !important; height:100% important}</style>\"))\n",
    "plot_width  = int(1200)\n",
    "plot_height = int(plot_width//1.2)\n",
    "\n",
    "\n",
    "####################################### Set data directories ##########################################\n",
    "start_dir=os.getcwd() # Base directory (used for relative paths)\n",
    "MTX_DATA_DIR = \"MTX\" # Input data directory containing matrix market matrices (used for plotting and AMGX solves)\n",
    "PKL_DATA_DIR = \"MTX_PKL\" # Output data directory for pickled dataframes (used for plotting)\n",
    "PETSC_DATA_DIR = \"MTX_PETSC\" # INPUT/OUTPUT directory for petsc matrices (used for petsc and slepc solves)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Matrix market matrices and pickle data (For visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "n_max_num_matrices_per_file = 2\n",
    "n_max_lines = sys.maxsize\n",
    "\n",
    "start = timer()\n",
    "regex_start = r\"%%MatrixMarket\"                             # Start of matrix read:    %%MatrixMarket\n",
    "regex_dims = r\"([0-9]+)\\s+([0-9]+)\\s+([0-9]+)\"              # Matrix dimensions:       int int int\n",
    "regex_element = r\"\\s*([0-9]+)\\s+([0-9]+)\\s+([0-9\\+\\-\\.e]+)\" # Repeated Matrix entries: int int float\n",
    "os.chdir(start_dir)\n",
    "print(f\"running in {os.getcwd()}\")\n",
    "max_row_id = -1\n",
    "max_col_id = -1\n",
    "min_val = sys.maxsize\n",
    "max_val = -sys.maxsize\n",
    "n_lower = 0\n",
    "n_upper = 0\n",
    "n_zero = 0\n",
    "n_diag = 0\n",
    "n_lines = 0\n",
    "data_frames = OrderedDict()\n",
    "file_list = {}\n",
    "\n",
    "for file in os.listdir(MTX_DATA_DIR):\n",
    "    if file.endswith(\".mtx\"):\n",
    "        file_list[file] = open(os.path.join(MTX_DATA_DIR, file),'r')\n",
    "    \n",
    "if not os.path.isdir(PKL_DATA_DIR):\n",
    "    os.mkdir(os.path.join(os.getcwd(), PKL_DATA_DIR))\n",
    "os.chdir(PKL_DATA_DIR)\n",
    "\n",
    "# Looad matrix market format matrix from one of more files (one per file)\n",
    "for file, file_handle in file_list.items():\n",
    "    orig_file_name = pathlib.Path(file).name\n",
    "    file_name = re.sub(\"/\",\"-\",orig_file_name)\n",
    "    data_name = \"\"\n",
    "    mat_num = 0\n",
    "    read_matrix = False\n",
    "    get_matrix_dims = False\n",
    "    with file_handle as file:\n",
    "        for line in file:\n",
    "            n_lines += 1\n",
    "            if n_lines > n_max_lines:\n",
    "                break\n",
    "            # Check for start of matrix (%%MatrixMarket)\n",
    "            if re.match(regex_start, line):\n",
    "                read_matrix = True\n",
    "                get_matrix_dims = True\n",
    "                nans = 0\n",
    "                n_data = 0\n",
    "                d_s = {'row': [], 'col': [], 'val': [] }\n",
    "                continue\n",
    "            # Check for dimensions (int int int)\n",
    "            if read_matrix and get_matrix_dims:\n",
    "                dims = re.match(regex_dims, line)\n",
    "                if dims:\n",
    "                    dim1 = dims.group(1)\n",
    "                    dim2 = dims.group(2)\n",
    "                    dim3 = dims.group(3)\n",
    "                    print(f\"MATRIX{str(mat_num)} dimensions: {dim1} {dim2} {dim3}\")\n",
    "                    read_matrix = True\n",
    "                    get_matrix_dims = False\n",
    "                    continue\n",
    "            # Check for element (int int float)\n",
    "            if read_matrix:\n",
    "                if re.search(regex_element, line):\n",
    "                    matches = re.finditer(regex_element, line)\n",
    "                    for matchNum, match in enumerate(matches):\n",
    "                        for groupNum in range(1, len(match.groups()) + 1):\n",
    "                            if groupNum == 1:\n",
    "                                row = int(match.group(groupNum))\n",
    "                            elif groupNum == 2:\n",
    "                                col = int(match.group(groupNum))\n",
    "                            elif groupNum == 3:\n",
    "                                val = float(match.group(groupNum))\n",
    "                    n_data += 1\n",
    "                    d_s['row'].append(row)\n",
    "                    d_s['col'].append(col)\n",
    "                    d_s['val'].append(val)\n",
    "                    if math.isnan(val):\n",
    "                        nans += 1\n",
    "                    max_row_id = max(max_row_id, row)\n",
    "                    max_col_id = max(max_col_id, col)\n",
    "                    min_val = min(min_val, val)\n",
    "                    max_val = max(max_val, val) \n",
    "                    if abs(val) > 0.0:\n",
    "                        if row > col:\n",
    "                            n_lower += 1\n",
    "                        elif col > row:\n",
    "                            n_upper += 1\n",
    "                        else:\n",
    "                            n_diag += 1\n",
    "                    else:\n",
    "                        n_zero += 1\n",
    "        # Dump pickle file\n",
    "        filename = f\"{orig_file_name}_MATRIX{str(mat_num)}_{dim1}_{dim2}_{dim3}\"\n",
    "        print(f\"End of {filename} (records={n_data}, nans={nans})\")\n",
    "        data_frames[data_name] = pd.DataFrame(data=d_s)\n",
    "        pickle_file_name = filename + \".p\"\n",
    "        f = open(pickle_file_name, 'wb')\n",
    "        pickle.dump(data_frames[data_name], f, protocol=4)\n",
    "        print(\"created pickle file \" + pickle_file_name)\n",
    "        f.close()\n",
    "        mat_num += 1\n",
    "        read_matrix = False\n",
    "        get_matrix_dims = False\n",
    "\n",
    "os.chdir(start_dir)\n",
    "data_frames = OrderedDict()\n",
    "for file in os.listdir(PKL_DATA_DIR):\n",
    "    if file.endswith(\".p\"):\n",
    "        file_name = PKL_DATA_DIR + \"-\" + re.split('\\.',file)[0]\n",
    "        f = open(os.path.join(PKL_DATA_DIR, file), 'rb')\n",
    "        data_frames[file_name] = pickle.load(f, encoding='bytes')\n",
    "        print(\"loaded \" + file_name)\n",
    "        f.close()\n",
    "\n",
    "end = timer()\n",
    "print(\"Data input complete: \" + str(n_lines) + \" lines. \" + str(end - start) + \" s\")\n",
    "print(\"diag, lower, upper, zero: \" + \", \".join([str(n_diag), str(n_lower), str(n_upper), str(n_zero)]))\n",
    "import io\n",
    "print (io.DEFAULT_BUFFER_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read pickle files (Fast data reload for visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle files to speed up load of large matrices, for plotting\n",
    "start = timer()\n",
    "os.chdir(start_dir)\n",
    "data_frames = OrderedDict()\n",
    "for file in os.listdir(PKL_DATA_DIR):\n",
    "    if file.endswith(\".p\"):\n",
    "        file_name = PKL_DATA_DIR + \"-\" + re.split('\\.',file)[0]\n",
    "        f = open(os.path.join(PKL_DATA_DIR, file), 'rb')\n",
    "        data_frames[file_name] = pickle.load(f, encoding='bytes')\n",
    "        print(\"loaded \" + file_name)\n",
    "        f.close() \n",
    "end = timer()\n",
    "print(str(end - start) + \" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import datashader as ds\n",
    "import pandas as pd\n",
    "import holoviews.operation.datashader as hd\n",
    "from holoviews.operation.datashader import aggregate, shade, datashade, dynspread, stack\n",
    "from holoviews.streams import RangeXY\n",
    "from datashader import transfer_functions as tf\n",
    "from holoviews.operation import decimate\n",
    "from datashader.colors import Sets1to3 # default datashade() and shade() color cycle\n",
    "hv.extension('bokeh')\n",
    "hv.notebook_extension('bokeh')\n",
    "decimate.max_samples=1000\n",
    "dynspread.max_px=20\n",
    "dynspread.threshold=0.5\n",
    "\n",
    "%opts RGB [width=plot_width, height=plot_height, invert_xaxis=False, invert_yaxis=True, xaxis='top'] {+axiswise}\n",
    "\n",
    "scatter_dict = {}\n",
    "color_key = [('positive', '#247ffe'), ('negative', '#e65036')]\n",
    "colors = hv.NdOverlay({k: hv.Points([0,0], label=str(k)).opts(style=dict(color=v)) for k, v in color_key})\n",
    "for data_name in data_frames:\n",
    "    df = data_frames[data_name]\n",
    "    plot = {'negative': hv.Scatter(df.loc[(df['val'] < 0.0)], kdims=['col', 'row']), 'positive': hv.Scatter(df.loc[(df['val'] > 0.0)], kdims=['col', 'row'])}\n",
    "    plot_data = hv.NdOverlay(plot, kdims='sign')\n",
    "    scatter_dict[data_name] = plot_data\n",
    "\n",
    "hmap = dynspread(datashade(hv.HoloMap(scatter_dict, kdims=['data_name']), aggregator=ds.count_cat('sign')), threshold=0.75, how='over') * colors\n",
    "hmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Aggregate Data (dynamic min, mean, max within window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import datashader as ds\n",
    "import pandas as pd\n",
    "import holoviews.operation.datashader as hd\n",
    "from holoviews.operation.datashader import aggregate, shade, datashade, dynspread, stack\n",
    "from holoviews.streams import RangeXY\n",
    "import colorcet as cc\n",
    "from datashader import transfer_functions as tf\n",
    "from holoviews.operation import decimate\n",
    "from datashader.colors import Sets1to3 # default datashade() and shade() color cycle\n",
    "hv.extension('bokeh')\n",
    "hv.notebook_extension('bokeh')\n",
    "decimate.max_samples=1000\n",
    "dynspread.max_px=20\n",
    "dynspread.threshold=0.5\n",
    "\n",
    "%opts QuadMesh [tools=['hover']] (alpha=0 hover_alpha=0.2)\n",
    "%opts RGB [width=plot_width, height=plot_height, invert_xaxis=False, invert_yaxis=True, xaxis='top'] {+axiswise}\n",
    "\n",
    "ccmap = list(reversed(cc.b_diverging_bwr_55_98_c37))\n",
    "\n",
    "# Set aggregate type for window\n",
    "aggregate_type = \"mean\" \n",
    "if aggregate_type == \"mean\": # Display mean value of data within window\n",
    "    aggr = ds.mean('val')\n",
    "elif aggregate_type == \"min\": # Display min value of data within window\n",
    "    aggr = ds.min('val')\n",
    "elif aggregate_type == \"max\": # Display max value of data within window\n",
    "    aggr = ds.max('val')\n",
    "elif aggregate_type == \"variance\": # Display variance of data within window\n",
    "    aggr = ds.var('val')\n",
    "elif aggregate_type == \"count\": # Display number of data elements within window\n",
    "    aggr = ds.count('val')\n",
    "elif aggregate_type == \"sum\": # Display num of data within window\n",
    "    aggr = ds.sum('val')\n",
    "\n",
    "# Set data id to plot\n",
    "data_id = 0\n",
    "value_filter = 0.0\n",
    "data_names = []\n",
    "for data_name in data_frames:\n",
    "    print(\"data_id: \" + str(len(data_names)) + \", data_name: \" + data_name)\n",
    "    df = data_frames[data_name]\n",
    "    data_names.append(data_name)\n",
    "\n",
    "df = data_frames[data_names[data_id]]\n",
    "points = hv.Points(data=df.loc[(abs(df['val']) > value_filter)], kdims=['col','row'],vdims =['val'])\n",
    "pts = dynspread(datashade(points, width=plot_width, height=plot_height, \n",
    "                         aggregator=ds.mean('val'),normalization='eq_hist',\n",
    "                         cmap = ccmap), threshold=0.5, how='over')\n",
    "(pts * hv.util.Dynamic(hd.aggregate(points, width=15, height=15, streams=[RangeXY],aggregator=aggr),\n",
    "                               operation=hv.QuadMesh).relabel(\"Dynamic hover\"))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save PETSC matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import petsc\n",
    "\n",
    "# export PETSC_CONFIGURE_OPTIONS=\"--download-fblaslapack=1\"\n",
    "\n",
    "# Convert matrix market matrices to PETSc binary format\n",
    "petsc_path = os.path.dirname(petsc.__file__) # Get petsc install location\n",
    "os.environ['PETSC_DIR'] = petsc_path\n",
    "sys.path.insert(0, petsc_path+'/lib/petsc/bin/pythonscripts/')\n",
    "sys.path.insert(0, petsc_path+'/lib/petsc/bin/')\n",
    "\n",
    "import PetscBinaryIO\n",
    "\n",
    "print(\"PETSC_DIR=\" + petsc_path)\n",
    "\n",
    "file_list = {}\n",
    "os.chdir(start_dir)\n",
    "for file in os.listdir(MTX_DATA_DIR):\n",
    "    if file.endswith(\".mtx\"):\n",
    "        file_list[os.path.join(MTX_DATA_DIR, file)] = open(os.path.join(MTX_DATA_DIR, file),'r')\n",
    "        \n",
    "if not os.path.isdir(PETSC_DATA_DIR):\n",
    "    os.mkdir(os.path.join(os.getcwd(), PETSC_DATA_DIR))\n",
    "    \n",
    "start = timer()\n",
    "for file, file_handle in file_list.items():\n",
    "    if file.endswith(\".mtx\"):\n",
    "        print(file)\n",
    "        output_file = re.split('\\.',file)[0]\n",
    "        print(output_file)\n",
    "        A = scipy.io.mmread(file)\n",
    "        mfile = open(re.sub(MTX_DATA_DIR, PETSC_DATA_DIR, output_file),'w')\n",
    "        PetscBinaryIO.PetscBinaryIO().writeMatSciPy(mfile, A)\n",
    "        print(\"converted \" + file)\n",
    "end = timer()\n",
    "print(str(end - start) + \" s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve with PETSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pylab\n",
    "import petsc4py\n",
    "from petsc4py import PETSc\n",
    "petsc4py.init(sys.argv)\n",
    "\n",
    "# Matrix to solve\n",
    "matrix_file = \"1138_bus\"\n",
    "\n",
    "# Load petsc binary matrix\n",
    "os.chdir(start_dir)\n",
    "os.chdir(PETSC_DATA_DIR)\n",
    "viewer = PETSc.Viewer().createBinary(matrix_file, 'r')\n",
    "A = PETSc.Mat().load(viewer)\n",
    "os.chdir(start_dir)\n",
    "\n",
    "# Initialise Krylov solver\n",
    "ksp = PETSc.KSP()\n",
    "ksp.create(PETSc.COMM_WORLD)\n",
    "\n",
    "# obtain sol & rhs vectors\n",
    "x, b = A.createVecs()\n",
    "x.set(0)\n",
    "b.set(1)\n",
    "ksp.setOperators(A)\n",
    "\n",
    "# Solver parameters:\n",
    "\n",
    "# use flexible gmres\n",
    "ksp.setType('fgmres')\n",
    "\n",
    "# use amg preconditioner\n",
    "ksp.getPC().setType('gamg')\n",
    "ksp.setConvergenceHistory(length=100, reset=False)\n",
    "ksp.setComputeSingularValues(True)\n",
    "r = ksp.getResidualNorm()\n",
    "ksp.logConvergenceHistory(r)\n",
    "ksp.setTolerances(rtol=0.000000001, max_it=100)\n",
    "ksp.setComputeEigenvalues(True)\n",
    "\n",
    "# Solve Ax = b\n",
    "start = timer()\n",
    "ksp.solve(b, x)\n",
    "end = timer()\n",
    "\n",
    "# Obtain eigenvalue data\n",
    "eigen = ksp.computeEigenvalues()\n",
    "(A, P) = ksp.getOperators()\n",
    "n = ksp.getIterationNumber()\n",
    "smin, smax = ksp.computeExtremeSingularValues()\n",
    "\n",
    "# Solver output\n",
    "print(f\"extreme singular values: {str(smin)},{str(smax)}\")\n",
    "print(f\"iterations: {str(n)}\")\n",
    "print(x[0:3])\n",
    "print(f\"solve time: {str(end - start)}\")\n",
    "\n",
    "# Plot solution, eigenvalues and residual reduction\n",
    "fig, axs = pylab.subplots(3)\n",
    "fig.tight_layout(pad=3.0)\n",
    "#axs[0].hist(eigen.real, 50, normed=1, facecolor='green', alpha=0.75)\n",
    "axs[0].scatter(eigen.real, eigen.imag, color='b')\n",
    "axs[1].plot(x)\n",
    "axs[2].plot(ksp.getConvergenceHistory()[1:])\n",
    "axs[2].set_yscale(\"log\")\n",
    "axs[0].set_title(\"eigenvalues\")\n",
    "axs[1].set_title(\"solution\")\n",
    "axs[2].set_title(\"residual reduction\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze eigenvalues with SLEPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pylab\n",
    "import slepc4py\n",
    "import petsc4py\n",
    "slepc4py.init(sys.argv)\n",
    "from petsc4py import PETSc\n",
    "from slepc4py import SLEPc\n",
    "\n",
    "# Matrix to analyze\n",
    "matrix_file = \"1138_bus\"\n",
    "\n",
    "def print_results(title, E, axs, color):\n",
    "\n",
    "    print()\n",
    "    print(f\"*** {title} ***\")\n",
    "    print()\n",
    "\n",
    "    its = E.getIterationNumber()\n",
    "    print(\"Number of iterations of the method: %d\" % its)\n",
    "\n",
    "    eps_type = E.getType()\n",
    "    print(\"Solution method: %s\" % eps_type)\n",
    "\n",
    "    nev, ncv, mpd = E.getDimensions()\n",
    "    print(\"Number of requested eigenvalues: %d\" % nev)\n",
    "\n",
    "    tol, maxit = E.getTolerances()\n",
    "    print(\"Stopping condition: tol=%.4g, maxit=%d\" % (tol, maxit))\n",
    "\n",
    "    nconv = E.getConverged()\n",
    "    print(\"Number of converged eigenpairs %d\" % nconv)\n",
    "\n",
    "    if nconv > 0:\n",
    "        x = []\n",
    "        y = []\n",
    "        # Create the results vectors\n",
    "        vr, wr = A.getVecs()\n",
    "        vi, wi = A.getVecs()\n",
    "        #\n",
    "        print()\n",
    "        print(\"        k          ||Ax-kx||/||kx|| \")\n",
    "        print(\"----------------- ------------------\")\n",
    "        for i in range(nconv):\n",
    "            k = E.getEigenpair(i, vr, vi)\n",
    "            error = E.computeError(i)\n",
    "            if i < 3:\n",
    "                if k.imag != 0.0:\n",
    "                    print(\" %9f%+9f j %12g\" % (k.real, k.imag, error))\n",
    "                else:\n",
    "                    print(\" %12f      %12g\" % (k.real, error))\n",
    "            x.append(k.real)\n",
    "            y.append(k.imag)\n",
    "        print()\n",
    "        axs.scatter(x, y, color=color)\n",
    "        axs.set_title(title)\n",
    "\n",
    "# set maximum dimension for direct solve\n",
    "max_eigenpairs = 2000\n",
    "\n",
    "# Load PETSc binary matrix\n",
    "os.chdir(start_dir)\n",
    "os.chdir(PETSC_DATA_DIR)\n",
    "viewer = PETSc.Viewer().createBinary(matrix_file, 'r')\n",
    "A = PETSc.Mat().load(viewer)\n",
    "m = A.getSizes()\n",
    "print(f\"Matrix dimensions: {str(m)}\")\n",
    "os.chdir(start_dir)\n",
    "\n",
    "# Initialize SLEPc solver\n",
    "E = SLEPc.EPS()\n",
    "E.create()\n",
    "E.setOperators(A)\n",
    "E.setProblemType(SLEPc.EPS.ProblemType.NHEP)\n",
    "\n",
    "start = timer()\n",
    "if m[0][0] > max_eigenpairs / 2:\n",
    "    \n",
    "    # Set plot parameters\n",
    "    fig, axs = pylab.subplots(2)\n",
    "    fig.tight_layout(pad=3.0)\n",
    "    \n",
    "    # KrylovSchur method for largest eigenvalues\n",
    "    E.setType(SLEPc.EPS.Type.KRYLOVSCHUR)\n",
    "    E.setWhichEigenpairs(SLEPc.EPS.Which.LARGEST_MAGNITUDE)\n",
    "    E.setDimensions(nev=(max_eigenpairs / 10))\n",
    "    E.solve()\n",
    "    print_results(\"KRYLOVSHCUR Largest\", E, axs[0], 'r')\n",
    "    \n",
    "    # KylovSchur method with harmonic extraction for smallest eigenvalues\n",
    "    E.setType(SLEPc.EPS.Type.KRYLOVSCHUR)\n",
    "    E.setWhichEigenpairs(SLEPc.EPS.Which.SMALLEST_MAGNITUDE)\n",
    "    E.setExtraction(SLEPc.EPS.Extraction.HARMONIC)\n",
    "    E.setDimensions(nev=(max_eigenpairs / 10))\n",
    "    E.solve()\n",
    "    print_results(\"KRYLOVSHCUR Smallest\", E, axs[1], 'g')\n",
    "else:\n",
    "    \n",
    "    # Direct solve using LAPACK\n",
    "    fig, axs = pylab.subplots(1)\n",
    "    fig.tight_layout(pad=3.0)\n",
    "    E.setType(SLEPc.EPS.Type.LAPACK)\n",
    "    E.solve()\n",
    "    print_results(\"LAPACK Solve\", E, axs[0], 'b')\n",
    "\n",
    "end = timer()\n",
    "print(f\"Computation time: {str(end - start)}\")\n",
    "\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve with AMGX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as splinalg\n",
    "import scipy.io\n",
    "import pyamgx\n",
    "\n",
    "# Matrix to solve\n",
    "matrix_file = \"1138_bus.mtx\"\n",
    "\n",
    "# Initialize amgx, unless already initialized\n",
    "try:\n",
    "    pyamgx.initialize()\n",
    "except:\n",
    "    print(\"failed to initialize amgx: attmpting to reinitialize\")\n",
    "    pyamgx.finalize()\n",
    "    pyamgx.initialize()\n",
    "finally:\n",
    "    print(\"Initialized amgx\")\n",
    "    \n",
    "\n",
    "# Initialize config and resources:\n",
    "cfg_dict = {\n",
    "    \"config_version\": 2, \n",
    "    \"determinism_flag\": 1,\n",
    "    \"exception_handling\" : 1,\n",
    "    \"solver\": {\n",
    "        \"print_grid_stats\": 1, \n",
    "        \"store_res_history\": 1, \n",
    "        \"solver\": \"GMRES\", \n",
    "        \"print_solve_stats\": 1, \n",
    "        \"obtain_timings\": 1, \n",
    "        \"preconditioner\": {\n",
    "            \"interpolator\": \"D2\", \n",
    "            \"print_grid_stats\": 1, \n",
    "            \"solver\": \"AMG\", \n",
    "            \"smoother\": \"JACOBI_L1\", \n",
    "            \"presweeps\": 2, \n",
    "            \"selector\": \"PMIS\", \n",
    "            \"coarsest_sweeps\": 2, \n",
    "            \"coarse_solver\": \"NOSOLVER\", \n",
    "            \"max_iters\": 1, \n",
    "            \"interp_max_elements\": 4, \n",
    "            \"min_coarse_rows\": 2, \n",
    "            \"scope\": \"amg_solver\", \n",
    "            \"max_levels\": 24, \n",
    "            \"cycle\": \"V\", \n",
    "            \"postsweeps\": 2\n",
    "        }, \n",
    "        \"max_iters\": 100, \n",
    "        \"monitor_residual\": 1, \n",
    "        \"gmres_n_restart\": 10, \n",
    "        \"convergence\": \"RELATIVE_INI_CORE\", \n",
    "        \"tolerance\": 1e-06, \n",
    "        \"norm\": \"L2\"\n",
    "   }\n",
    "}\n",
    "cfg = pyamgx.Config().create_from_dict(cfg_dict)\n",
    "rsc = pyamgx.Resources().create_simple(cfg)\n",
    "\n",
    "# Create matrices and vectors:\n",
    "A = pyamgx.Matrix().create(rsc)\n",
    "b = pyamgx.Vector().create(rsc)\n",
    "x = pyamgx.Vector().create(rsc)\n",
    "\n",
    "# Create solver:\n",
    "solver = pyamgx.Solver().create(rsc, cfg)\n",
    "\n",
    "# Load matrix market format matrix\n",
    "os.chdir(start_dir)\n",
    "os.chdir(MTX_DATA_DIR)\n",
    "M = sparse.csr_matrix(scipy.io.mmread(matrix_file))\n",
    "os.chdir(start_dir)\n",
    "\n",
    "rhs = np.ones(M.shape[0])\n",
    "sol = np.zeros(M.shape[0])\n",
    "A.upload_CSR(M)\n",
    "b.upload(rhs)\n",
    "x.upload(sol)\n",
    "\n",
    "# Setup\n",
    "solver.setup(A)\n",
    "\n",
    "# Solve system\n",
    "start = timer()\n",
    "solver.solve(b, x)\n",
    "end = timer()\n",
    "\n",
    "# Download solution\n",
    "x.download(sol)\n",
    "n = solver.iterations_number\n",
    "\n",
    "print(\"pyamgx solution: \", sol)\n",
    "print(f\"iterations: {n}\")\n",
    "#print(\"scipy solution: \", splinalg.spsolve(M, rhs))\n",
    "print(f\"solve time: {str(end - start)}\")\n",
    "\n",
    "# Clean up:\n",
    "A.destroy()\n",
    "x.destroy()\n",
    "b.destroy()\n",
    "solver.destroy()\n",
    "rsc.destroy()\n",
    "cfg.destroy()\n",
    "\n",
    "pyamgx.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MatrixViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import holoviews as hv\n",
    "import datashader as ds\n",
    "import pandas as pd\n",
    "import holoviews.operation.datashader as hd\n",
    "from holoviews.operation.datashader import aggregate, shade, datashade, dynspread, stack\n",
    "from datashader import transfer_functions as tf\n",
    "from holoviews.operation import decimate\n",
    "from IPython.core.display import display, HTML\n",
    "from datashader.colors import Sets1to3 # default datashade() and shade() color cycle\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "display(HTML(\"<style>.container { width:100% !important; height:100% important}</style>\"))\n",
    "hv.extension('bokeh')\n",
    "hv.notebook_extension('bokeh')\n",
    "decimate.max_samples=1000\n",
    "dynspread.max_px=20\n",
    "dynspread.threshold=0.5\n",
    "plot_width  = int(1200)\n",
    "plot_height = int(plot_width//1.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.help(datashade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data and dump pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "n_max_num_matrices_per_file = 2\n",
    "n_max_lines = sys.maxsize\n",
    "\n",
    "start = timer()\n",
    "file_list = [\"MATRICES/matrix.txt\"] # List of matries to read in\n",
    "n_lines = 0\n",
    "regex_1 = r\" *G *= *\\[\"  # Start of matrix read\n",
    "regex_2 = r\" *([0-9]+) *([0-9]+) *([0-9\\+-\\.e]+)\" # Matrix entries: int int float\n",
    "regex_3 = r\" *\\]\" # End of matrix read\n",
    "max_row_id = -1\n",
    "max_col_id = -1\n",
    "min_val = sys.maxsize\n",
    "max_val = -sys.maxsize\n",
    "n_lower = 0\n",
    "n_upper = 0\n",
    "n_zero = 0\n",
    "n_diag = 0\n",
    "data_frames = OrderedDict()\n",
    "for file in file_list:\n",
    "    orig_file_name = re.split('\\.',file)[0]\n",
    "    file_name = re.sub(\"/\",\"-\",orig_file_name)\n",
    "    data_name = \"\"\n",
    "    mat_num = 0\n",
    "    read_matrix = False\n",
    "    with open(file,'r') as file:\n",
    "        for line in file:\n",
    "            n_lines += 1\n",
    "            if n_lines > n_max_lines:\n",
    "                break\n",
    "            if re.match(regex_1, line):\n",
    "                read_matrix = True\n",
    "                data_name = file_name + \"-G\" + str(mat_num)\n",
    "                print(data_name)\n",
    "                d_s = {'row': [], 'col': [], 'val': [] }\n",
    "                continue\n",
    "            if read_matrix and re.match(regex_3, line):\n",
    "                print(\"End of \" + data_name)\n",
    "                data_frames[data_name] = pd.DataFrame(data=d_s)\n",
    "                pickle_file_name = orig_file_name + \"-G\" + str(mat_num) + \".p\"\n",
    "                f = open(pickle_file_name, 'wb')\n",
    "                pickle.dump(data_frames[data_name], f, protocol=4)\n",
    "                print(\"created pickle file \" + pickle_file_name)\n",
    "                f.close()\n",
    "                mat_num += 1\n",
    "                if mat_num == n_max_num_matrices_per_file:\n",
    "                    break\n",
    "                else:\n",
    "                    read_matrix = False\n",
    "                    continue\n",
    "            if read_matrix:\n",
    "                matches = re.finditer(regex_2, line)\n",
    "                for matchNum, match in enumerate(matches):\n",
    "                    for groupNum in range(1, len(match.groups()) + 1):\n",
    "                        if groupNum == 1:\n",
    "                            row = int(match.group(groupNum))\n",
    "                        elif groupNum == 2:\n",
    "                            col = int(match.group(groupNum))\n",
    "                        elif groupNum == 3:\n",
    "                            val = float(match.group(groupNum))\n",
    "                d_s['row'].append(row)\n",
    "                d_s['col'].append(col)\n",
    "                d_s['val'].append(val)\n",
    "                max_row_id = max(max_row_id, row)\n",
    "                max_col_id = max(max_col_id, col)\n",
    "                min_val = min(min_val, val)\n",
    "                max_val = max(max_val, val)     \n",
    "                if abs(val) > 0.0:\n",
    "                    if row > col:\n",
    "                        n_lower += 1\n",
    "                    elif col > row:\n",
    "                        n_upper += 1\n",
    "                    else:\n",
    "                        n_diag += 1\n",
    "                else:\n",
    "                    n_zero += 1\n",
    "end = timer()\n",
    "print(\"Data input complete: \" + str(n_lines) + \" lines. \" + str(end - start) + \" s\")\n",
    "print(\"diag, lower, upper, zero: \" + \", \".join([str(n_diag), str(n_lower), str(n_upper), str(n_zero)]))\n",
    "import io\n",
    "print (io.DEFAULT_BUFFER_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read pickle files (For fast data load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "start = timer()\n",
    "file_directories = [\"MATRICES\"] # List of directories containing pickled matrix files\n",
    "data_frames = OrderedDict()\n",
    "for directory in file_directories:\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".p\"):\n",
    "            file_name = directory + \"-\" + re.split('\\.',file)[0]\n",
    "            f = open(os.path.join(directory, file), 'rb')\n",
    "            data_frames[file_name] = pickle.load(f, encoding='bytes')\n",
    "            print(\"loaded \" + file_name)\n",
    "            f.close() \n",
    "end = timer()\n",
    "print(str(end - start) + \" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%opts RGB [width=plot_width, height=plot_height, invert_xaxis=False, invert_yaxis=True, xaxis='top'] {+axiswise}\n",
    "scatter_dict = {}\n",
    "color_key = [('positive', '#247ffe'), ('negative', '#e65036')]\n",
    "colors = hv.NdOverlay({k: hv.Points([0,0], label=str(k)).opts(style=dict(color=v)) for k, v in color_key})\n",
    "for data_name in data_frames:\n",
    "    df = data_frames[data_name]\n",
    "    plot = {'negative': hv.Scatter(df.loc[(df['val'] < 0.0)], kdims=['col', 'row']), 'positive': hv.Scatter(df.loc[(df['val'] > 0.0)], kdims=['col', 'row'])}\n",
    "    plot_data = hv.NdOverlay(plot, kdims='sign')\n",
    "    scatter_dict[data_name] = plot_data\n",
    "\n",
    "hmap = dynspread(datashade(hv.HoloMap(scatter_dict, kdims=['data_name']), aggregator=ds.count_cat('sign')), threshold=0.75, how='over') * colors\n",
    "hmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Aggregate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts QuadMesh [tools=['hover']] (alpha=0 hover_alpha=0.2)\n",
    "%%opts RGB [width=plot_width, height=plot_height, invert_xaxis=False, invert_yaxis=True, xaxis='top'] {+axiswise}\n",
    "from holoviews.streams import RangeXY\n",
    "import colorcet as cc\n",
    "ccmap = list(reversed(cc.b_diverging_bwr_55_98_c37))\n",
    "\n",
    "# Set aggregate type\n",
    "aggregate_type = \"mean\" \n",
    "if aggregate_type == \"mean\": # Display mean value of data within window\n",
    "    aggr = ds.mean('val')\n",
    "elif aggregate_type == \"min\": # Display min value of data within window\n",
    "    aggr = ds.min('val')\n",
    "elif aggregate_type == \"max\": # Display max value of data within window\n",
    "    aggr = ds.max('val')\n",
    "elif aggregate_type == \"variance\": # Display variance of data within window\n",
    "    aggr = ds.var('val')\n",
    "elif aggregate_type == \"count\": # Display number of data elements within window\n",
    "    aggr = ds.count('val')\n",
    "elif aggregate_type == \"sum\": # Display num of data within window\n",
    "    aggr = ds.sum('val')\n",
    "\n",
    "\n",
    "data_id = 0\n",
    "value_filter = 0.0\n",
    "data_names = []\n",
    "for data_name in data_frames:\n",
    "    print(\"data_id: \" + str(len(data_names)) + \", data_name: \" + data_name)\n",
    "    df = data_frames[data_name]\n",
    "    data_names.append(data_name)\n",
    "\n",
    "df = data_frames[data_names[data_id]]\n",
    "points = hv.Points(data=df.loc[(abs(df['val']) > value_filter)], kdims=['col','row'],vdims =['val'])\n",
    "pts = dynspread(datashade(points, width=plot_width, height=plot_height, \n",
    "                         aggregator=ds.mean('val'),normalization='eq_hist',\n",
    "                         cmap = ccmap), threshold=0.5, how='over')\n",
    "(pts * hv.util.Dynamic(hd.aggregate(points, width=15, height=15, streams=[RangeXY],aggregator=aggr),\n",
    "                               operation=hv.QuadMesh).relabel(\"Dynamic hover\"))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
